{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdminGPT: Your AI-Powered Administrative Assistant, powered by OpenAI's Assistant Framework  ðŸš€\n",
    "### Introduction\n",
    "AdmiGPT is an AI-powered administrative assistant, harnessing the power of OpenAI's Assistant framework to seamlessly integrate with your email and calendar. Similar to Microsoft's Copilot, only better, it's designed to be your ultimate productivity partner, AdmiGPT offers an array of advanced features, making your administrative tasks simpler, faster, and more efficient.\n",
    "\n",
    "AdminGPT is fully Open Source, so everything you need to run it for yourself is in this Github repo. This notebook helps you get started with AdminGPT, and walks you through how it's implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "To begin, we're going to load our custom OpenAI Tools, which will interface with your email platform's API, and store any confidential and authentication information for the user in environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time, json, pprint, os\n",
    "from tools.o365_toolkit import (\n",
    "    o365search_emails,\n",
    "    o365search_email,\n",
    "    o365search_events,\n",
    "    o365parse_proposed_times,\n",
    "    o365send_message,\n",
    "    o365send_event,\n",
    "    tools,\n",
    ")\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Set your name\n",
    "os.environ[\"CLIENT_NAME\"] = \"Your Name\"\n",
    "# Set your email\n",
    "os.environ[\"CLIENT_EMAIL\"] = \"Your Email\"\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "# Set your Microsoft Graph client ID\n",
    "os.environ[\"CLIENT_ID\"] = \"Your MS Graph Client ID\"\n",
    "# Set your Microsoft Graph client secret\n",
    "os.environ[\"CLIENT_SECRET\"] = \"Your MS Graph Client Secret\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to set a few constants, which we will use throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_DELAY_SECONDS = 2\n",
    "debug = False\n",
    "assistant_name = \"Monica A. Ingenio\"\n",
    "model = \"gpt-4-1106-preview\"\n",
    "current_date = dt.now()\n",
    "formatted_date = current_date.strftime(\"%A, %B %d, %Y\")\n",
    "client_name = os.environ.get(\"CLIENT_NAME\")\n",
    "client_email = os.environ.get(\"CLIENT_EMAIL\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assistant_instructions = (\n",
    "    \"You are an AI Administrative Assistant called \"\n",
    "    + assistant_name\n",
    "    + \", and I am your executive. My name is \"\n",
    "    + client_name\n",
    "    + \". My email is: \"\n",
    "    + client_email\n",
    "    + \", in the Eastern Time (ET).\"\n",
    "    \" You have access to my email and calendar. Today is \"\n",
    "    + formatted_date\n",
    "    + \". \"\n",
    ")\n",
    "\n",
    "# Add the debug prompt if user runs with debug\n",
    "if debug:\n",
    "    debug_prompt = (\n",
    "        \"Keep a record of any feedback requests provided by me\"\n",
    "        \" detailing the prompt and tools calls in case I want to retrieve\"\n",
    "        \" them.\"\n",
    "    )\n",
    "else:\n",
    "    debug_prompt = \"\"    \n",
    "assistant_instructions = assistant_instructions + debug_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an OpenAI Assistant so we can interact with it, and a thread in which to run our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AI Administrative Assistant\",\n",
    "    instructions=assistant_instructions,\n",
    "    model=model,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make execution easier in the future steps, we create a function to run prompts with only one call. Then, we are going to use the function to submit the initial coaching prompt so that the Assistant gets better at performing tasks from the beginning. (A big part of the secret sauce of AdminGPT is in the coaching data file called coaching_data.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt: str, thread_id, assistant_id):\n",
    "    message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=prompt,\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    return run\n",
    "\n",
    "with open(\"coaching_data.txt\", \"r\") as file:\n",
    "    prompt = file = file.read()\n",
    "\n",
    "run = run_prompt(prompt, thread.id, assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further make execution easier in future steps, we Create a function that polls the OpenAI API for a response to the prompt and executes tool calls, so we can use it to retrieve responses in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_for_response(thread_id, run_id):\n",
    "\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id, run_id=run_id\n",
    "        )\n",
    "        status = run.status\n",
    "\n",
    "        if status == \"completed\":\n",
    "            response = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            if response.data:\n",
    "                return(response.data[0].content[0].text.value)\n",
    "            break\n",
    "        elif status == \"requires_action\":\n",
    "            tools_outputs = []\n",
    "\n",
    "            for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                tool_call_id = tool_call.id\n",
    "                function_name = tool_call.function.name\n",
    "                function_arguments = tool_call.function.arguments\n",
    "                function_arguments = json.loads(function_arguments)\n",
    "\n",
    "                # Case statement to execute each toolkit function\n",
    "                if function_name == \"o365search_emails\":\n",
    "                    output = o365search_emails(**function_arguments)\n",
    "                elif function_name == \"o365search_email\":\n",
    "                    output = o365search_email(**function_arguments)\n",
    "                elif function_name == \"o365search_events\":\n",
    "                    output = o365search_events(**function_arguments)\n",
    "                elif function_name == \"o365parse_proposed_times\":\n",
    "                    output = o365parse_proposed_times(\n",
    "                        **function_arguments, client=client, model=model\n",
    "                    )\n",
    "                elif function_name == \"o365send_message\":\n",
    "                    output = o365send_message(**function_arguments)\n",
    "                elif function_name == \"o365send_event\":\n",
    "                    output = o365send_event(**function_arguments)\n",
    "\n",
    "                # Clean the function output into JSON-like output\n",
    "                output = pprint.pformat(output)\n",
    "                tool_output = {\"tool_call_id\": tool_call_id, \"output\": output}\n",
    "                tools_outputs.append(tool_output)\n",
    "\n",
    "            if run.required_action.type == \"submit_tool_outputs\":\n",
    "                client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run_id, tool_outputs=tools_outputs\n",
    "                )\n",
    "\n",
    "        elif status == \"failed\":\n",
    "            return(\"Run failed try again!\")\n",
    "            break\n",
    "\n",
    "        time.sleep(LOOP_DELAY_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've submit our first prompt, we are going to poll for a response. If the response is, \"How can I help you?\", we know that the coaching data was sent correctly, and we are ready to start using AdminGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I help you?\n"
     ]
    }
   ],
   "source": [
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we're going to perform the most simple task, which is summarizing an email from a specific sender. In this case, I chose a promotional email I received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Hess shared Maven Associates' 2023 Q4 update, focusing on economic challenges and highlighting the company's growth and partnerships.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please summarize in a very short sentence the most recent email from Mark Hess\"\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to respond to Mark's email, letting him know we're not interested, with AdminGPT drafting the content for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly, here's a draft of the email to Mark Hess:\n",
      "\n",
      "---\n",
      "\n",
      "Subject: RE: The Maven Newsletter - Winter 2023 Recap\n",
      "\n",
      "Dear Mark,\n",
      "\n",
      "Thank you for keeping us informed with the Maven Associates' quarterly update. We appreciate the insight, but currently, we will not be engaging further on this matter.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "If this email looks good to you, please let me know, and I will send it.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please draft a short email to Mark letting him know we're not interested. Please show me the email before sending.\"\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to highlight a few things in this response because AdminGPT knew a lot of information with us telling them. First, it knew which Mark I was talking about, because it has access to this complete interaction. It also knew my name, which we sent as part of the original Assistant instructions. Finally, it knew how to bring it all together to write a courteous and clear email. This final step is when ChatGPT really shines by bringing different pieces of information together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
