{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdminGPT: Your AI-Powered Administrative Assistant, powered by OpenAI's Assistant Framework  ðŸš€\n",
    "### Introduction\n",
    "AdmiGPT is an AI-powered administrative assistant, harnessing the power of OpenAI's Assistant framework to seamlessly integrate with your email and calendar. Similar to Microsoft's Copilot, only better, it's designed to be your ultimate productivity partner, AdmiGPT offers an array of advanced features, making your administrative tasks simpler, faster, and more efficient.\n",
    "\n",
    "AdminGPT is fully Open Source, so everything you need to run it for yourself is in this Github repo. This notebook helps you get started with AdminGPT, and walks you through how it's implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "To begin, we're going to load our custom OpenAI Tools, which will interface with your email platform's API, and store any confidential and authentication information for the user in environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time, json, pprint, os\n",
    "from tools.o365_toolkit import (\n",
    "    o365search_emails,\n",
    "    o365search_email,\n",
    "    o365search_events,\n",
    "    o365parse_proposed_times,\n",
    "    o365send_message,\n",
    "    o365reply_message,\n",
    "    o365send_event,\n",
    "    o365find_free_time_slots,\n",
    "    tools,\n",
    ")\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Set your name\n",
    "os.environ[\"CLIENT_NAME\"] = \"YOUR NAME\"\n",
    "# Set your email\n",
    "os.environ[\"CLIENT_EMAIL\"] = \"YOUR EMAIL\"\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n",
    "# Set your Microsoft Graph client ID\n",
    "os.environ[\"CLIENT_ID\"] = \"YOUR ID\"\n",
    "# Set your Microsoft Graph client secret\n",
    "os.environ[\"CLIENT_SECRET\"] = \"YOUR SECRET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to set a few constants, which we will use throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP_DELAY_SECONDS = 2\n",
    "debug = False\n",
    "assistant_name = \"Monica A. Ingenio\"\n",
    "model = \"gpt-4-1106-preview\"\n",
    "current_date = dt.now()\n",
    "formatted_date = current_date.strftime(\"%A, %B %d, %Y\")\n",
    "client_name = os.environ.get(\"CLIENT_NAME\")\n",
    "client_email = os.environ.get(\"CLIENT_EMAIL\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assistant_instructions = (\n",
    "    \"You are an AI Administrative Assistant called \"\n",
    "    + assistant_name\n",
    "    + \", and I am your executive. My name is \"\n",
    "    + client_name\n",
    "    + \". My email is: \"\n",
    "    + client_email\n",
    "    + \", in the Eastern Time (ET). You have access to my email and calendar. Today is \"\n",
    "    + formatted_date\n",
    "    + \". \"\n",
    ")\n",
    "\n",
    "# Add the debug prompt if user runs with debug\n",
    "if debug:\n",
    "    debug_prompt = (\n",
    "        \"Keep a record of any feedback requests provided by me\"\n",
    "        \" detailing the prompt and tools calls in case I want to retrieve\"\n",
    "        \" them.\"\n",
    "    )\n",
    "else:\n",
    "    debug_prompt = \"\"\n",
    "assistant_instructions = assistant_instructions + debug_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an OpenAI Assistant so we can interact with it, and a thread in which to run our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AI Administrative Assistant\",\n",
    "    instructions=assistant_instructions,\n",
    "    model=model,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make execution easier in the future steps, we create a function to run prompts with only one call. Then, we are going to use the function to submit the initial coaching prompt so that the Assistant gets better at performing tasks from the beginning. (A big part of the secret sauce of AdminGPT is in the coaching data file called coaching_data.txt, which gives table-stakes knowledge to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt: str, thread_id, assistant_id):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=prompt,\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    return run\n",
    "\n",
    "\n",
    "with open(\"coaching_data.txt\", \"r\") as file:\n",
    "    prompt = file = file.read()\n",
    "\n",
    "run = run_prompt(prompt, thread.id, assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further make execution easier in future steps, we Create a function that polls the OpenAI API for a response to the prompt and executes tool calls, so we can use it to retrieve responses in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_for_response(thread_id, run_id):\n",
    "\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "        status = run.status\n",
    "\n",
    "        if status == \"completed\":\n",
    "            response = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            if response.data:\n",
    "                return response.data[0].content[0].text.value\n",
    "            break\n",
    "        elif status == \"requires_action\":\n",
    "            tools_outputs = []\n",
    "\n",
    "            for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                tool_call_id = tool_call.id\n",
    "                function_name = tool_call.function.name\n",
    "                function_arguments = tool_call.function.arguments\n",
    "                function_arguments = json.loads(function_arguments)\n",
    "\n",
    "                # Case statement to execute each toolkit function\n",
    "                if function_name == \"o365search_emails\":\n",
    "                    output = o365search_emails(**function_arguments)\n",
    "                elif function_name == \"o365search_email\":\n",
    "                    output = o365search_email(**function_arguments)\n",
    "                elif function_name == \"o365search_events\":\n",
    "                    output = o365search_events(**function_arguments)\n",
    "                elif function_name == \"o365parse_proposed_times\":\n",
    "                    output = o365parse_proposed_times(\n",
    "                        **function_arguments, client=client, model=model\n",
    "                    )\n",
    "                elif function_name == \"o365send_message\":\n",
    "                    output = o365send_message(**function_arguments)\n",
    "                elif function_name == \"o365send_event\":\n",
    "                    output = o365send_event(**function_arguments)\n",
    "                elif function_name == \"o365reply_message\":\n",
    "                    output = o365reply_message(**function_arguments)\n",
    "                elif function_name == \"o365find_free_time_slots\":\n",
    "                    output = o365find_free_time_slots(**function_arguments)\n",
    "\n",
    "                # Clean the function output into JSON-like output\n",
    "                output = pprint.pformat(output)\n",
    "                tool_output = {\"tool_call_id\": tool_call_id, \"output\": output}\n",
    "                tools_outputs.append(tool_output)\n",
    "\n",
    "            if run.required_action.type == \"submit_tool_outputs\":\n",
    "                client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run_id, tool_outputs=tools_outputs\n",
    "                )\n",
    "\n",
    "        elif status == \"failed\":\n",
    "            return \"Run failed try again!\"\n",
    "            break\n",
    "\n",
    "        time.sleep(LOOP_DELAY_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've submit our first prompt, we are going to poll for a response. If the response is, \"How can I help you?\", we know that the coaching data was sent correctly, and we are ready to start using AdminGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I help you?\n"
     ]
    }
   ],
   "source": [
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we're going to perform the most simple task, which is summarizing an email from a specific sender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from Santiago Delgado expresses curiosity about the possibility of Mike Portnoy rejoining Dream Theater. Santiago Delgado proposes a discussion on this topic and suggests meeting on February 3, 2024, at 4:00 pm ET. He recalls Mike Portnoy's significant role in the band's development and his departure in 2010 that led to his involvement in various other musical projects. Santiago Delgado is looking forward to hearing thoughts on whether Mike Portnoy's potential return could cause a resurgence of the band's classic sound or lead to unforeseen complications.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Can you please concisely summarize the most recent email from Santiago Delgado\"\n",
    "    \" including any proposed meeting times?\"\n",
    ")\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to show AdminGPT's ability to interact with your calendar. We're going to check what events we have on the day that the email proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/O365/utils/windows_tz.py:638: PytzUsageWarning: The zone attribute is specific to pytz's interface; please migrate to a new time zone provider. For more details on how to do so, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  iana_tz.zone if isinstance(iana_tz, tzinfo) else iana_tz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On February 3, 2024, the day Santiago Delgado proposes to meet, you have the following meetings scheduled:\n",
      "\n",
      "1. **Flight from Dallas to Cincinnati**\n",
      "   - From: 8:00 am ET\n",
      "   - Until: 10:30 am ET\n",
      "\n",
      "2. **Lunch Meeting with Management**\n",
      "   - From: 12:00 pm ET\n",
      "   - Until: 1:00 pm ET\n",
      "\n",
      "3. **Strategy Session**\n",
      "   - From: 3:00 pm ET\n",
      "   - Until: 5:00 pm ET\n",
      "\n",
      "4. **Flight from Cincinnati to Dallas**\n",
      "   - From: 6:00 pm ET\n",
      "   - Until: 8:30 pm ET\n",
      "\n",
      "Given this schedule, the proposed meeting time of 4:00 pm ET on February 3 intersects with the Strategy Session you have from 3:00 pm to 5:00 pm ET.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"What meetings do I have on the day that Santiago Delgado is proposing to meet in\"\n",
    "    \" his most email?\"\n",
    ")\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know when the email sender wants to meet, and what meetings I have on that day. So, let's see what times I have free that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On February 3, 2024, you are free during the following time slots:\n",
      "\n",
      "1. From midnight to 8:00 am ET\n",
      "2. From 10:30 am to 12:00 pm ET\n",
      "3. From 1:00 pm to 3:00 pm ET\n",
      "4. From 5:00 pm to 6:00 pm ET\n",
      "5. From 8:30 pm to 11:59:59 pm ET\n",
      "\n",
      "Therefore, considering the proposed meeting time of 4:00 pm ET by Santiago Delgado, you are not free as it clashes with your existing \"Strategy Session\" from 3:00 pm to 5:00 pm ET. However, you do have a free slot available just after that meeting, from 5:00 pm ET to 6:00 pm ET.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What times am I free on the day that Santiago is proposing to meet?\"\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this information, we can now draft a response to the email letting the sender know that we can't meet at the proposed time, and propose other times to meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draft response to Santiago has been saved with the subject \"Mike Portnoy coming back to Dream Theater?\". Here is the content of the draft:\n",
      "\n",
      "---\n",
      "\n",
      "Hi Santiago,\n",
      "\n",
      "Thank you for reaching out. Unfortunately, I have a prior engagement during the time you suggested for our discussion on Mike Portnoy's potential return to Dream Theater. However, I am available before and after certain appointments on the same day. Would any of the following times work for you?\n",
      "\n",
      "- From 10:30 am to 12:00 pm ET\n",
      "- From 1:00 pm to 3:00 pm ET\n",
      "- From 5:00 pm to 6:00 pm ET\n",
      "- After 8:30 pm ET\n",
      "\n",
      "Please let me know your preference and I'll make sure to block out the time on my calendar.\n",
      "\n",
      "Looking forward to our conversation.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you would like to send this draft or if you need any adjustments.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Please draft a response to Santiago letting him know that I can't meet on the\"\n",
    "    \" proposed times, and propose other free times on the same day. Show me the draft.\"\n",
    ")\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we will want the email to come from our AI administrative instead of the ourselves, so we can do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly, I will revise the draft so that it comes from me on your behalf. Here is the updated content:\n",
      "\n",
      "---\n",
      "\n",
      "Hi Santiago,\n",
      "\n",
      "I hope you are doing well. I am writing to you on behalf of Santiago Delgado to discuss your recent email regarding Mike Portnoy potentially rejoining Dream Theater. Unfortunately, Santiago is not available at the proposed time of 4:00 pm ET on February 3, 2024, due to prior commitments.\n",
      "\n",
      "However, he would be happy to discuss this with you at alternative times on the same day. The following slots are open on his calendar:\n",
      "\n",
      "- From 10:30 am to 12:00 pm ET\n",
      "- From 1:00 pm to 3:00 pm ET\n",
      "- From 5:00 pm to 6:00 pm ET\n",
      "- After 8:30 pm ET\n",
      "\n",
      "Please let me know if any of these times would be convenient for you, and we will schedule the meeting accordingly.\n",
      "\n",
      "Thank you for your understanding, and we look forward to the possibility of this discussion.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Monica A. Ingenio\n",
      "Administrative Assistant to Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "Before proceeding, does this updated draft meet your approval?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you edit the email and have it come from you on behalf of me?\"\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, I want to show that you can follow all these steps in one prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draft response to Santiago Delgado has been saved with the subject \"Mike Portnoy coming back to Dream Theater?\". Here is the content of the draft:\n",
      "\n",
      "---\n",
      "\n",
      "Dear Santiago Delgado,\n",
      "\n",
      "This is Monica A. Ingenio, Santiago Delgado's administrative assistant at ACON Investments. Unfortunately, Santiago has a prior commitment during the proposed time of 4:00 pm ET on February 3rd, 2024, and will not be able to meet then.\n",
      "\n",
      "However, he is available at other times on the same day and would be pleased to discuss the topic of Mike Portnoy and Dream Theater with you. Please find below the times he is available:\n",
      "\n",
      "- From 10:30 am to 12:00 pm ET\n",
      "- From 1:00 pm to 3:00 pm ET\n",
      "- From 5:00 pm to 6:00 pm ET\n",
      "- After 8:30 pm ET\n",
      "\n",
      "Please let us know which time works best for you so we can schedule the meeting accordingly.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Monica A. Ingenio\n",
      "Administrative Assistant to Santiago Delgado\n",
      "ACON Investments\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if this draft meets your expectations or if you would like any further changes.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Can you draft a response to Santiago Delgado's most recent email from you on\"\n",
    "    \" behalf of me letting him know if I can meet at the times he proposes, and if not,\"\n",
    "    \" propose other times on the same day? Show me the draft.\"\n",
    ")\n",
    "run = run_prompt(prompt, thread.id, assistant.id)\n",
    "response = poll_for_response(thread.id, run.id)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
