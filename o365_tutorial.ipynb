{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdminGPT: Your AI-Powered Administrative Assistant, powered by OpenAI's Assistant Framework  ðŸš€\n",
    "### Introduction\n",
    "AdmiGPT is an AI-powered administrative assistant, harnessing the power of OpenAI's Assistant framework to seamlessly integrate with your email and calendar. Similar to Microsoft's Copilot, only better, it's designed to be your ultimate productivity partner, AdmiGPT offers an array of advanced features, making your administrative tasks simpler, faster, and more efficient.\n",
    "\n",
    "AdminGPT is fully Open Source, so everything you need to run it for yourself is in this Github repo. This notebook helps you get started with AdminGPT, and walks you through how it's implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "To begin, we're going to load our custom OpenAI Tools, which will interface with your email platform's API, and store any confidential and authentication information for the user in environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time, json, pprint, os\n",
    "from tools.o365_toolkit import (\n",
    "    o365search_emails,\n",
    "    o365search_email,\n",
    "    o365search_events,\n",
    "    o365parse_proposed_times,\n",
    "    o365send_message,\n",
    "    o365reply_message,\n",
    "    o365send_event,\n",
    "    o365find_free_time_slots,\n",
    "    tools,\n",
    ")\n",
    "from datetime import datetime as dt\n",
    "from tools.utils import authenticate\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI KEY\"\n",
    "# Set your Microsoft Graph client ID\n",
    "os.environ[\"CLIENT_ID\"] = \"YOUR CLIENT ID\"\n",
    "# Set your Microsoft Graph client secret\n",
    "os.environ[\"CLIENT_SECRET\"] = \"YOUR CLIENT SECRET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to set a few constants, which we will use throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = authenticate()\n",
    "mailbox = account.mailbox()\n",
    "mailboxsettings = mailbox.get_settings()\n",
    "timezone = mailboxsettings.timezone\n",
    "directory = account.directory(resource=\"me\")\n",
    "user = directory.get_current_user()\n",
    "client_name = user.full_name\n",
    "client_email = user.mail\n",
    "\n",
    "# Set values for global variables\n",
    "assistant_name = \"Monica A. Ingenio\"\n",
    "current_date = dt.now()\n",
    "formatted_date = current_date.strftime(\"%A, %B %d, %Y\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "debug = False\n",
    "model = \"gpt-4-1106-preview\"\n",
    "assistant_instructions = (\n",
    "    \"You are an AI Administrative Assistant called \"\n",
    "    + assistant_name\n",
    "    + \", and I am your executive. My name is \"\n",
    "    + client_name\n",
    "    + \". My email is \"\n",
    "    + client_email\n",
    "    + \", and I am in the \"\n",
    "    + timezone\n",
    "    + \" timezone. You have access to my email and calendar. Today is \"\n",
    "    + formatted_date\n",
    "    + \". ALWAYS use functions for determining free times and parsing proposed\"\n",
    "    \" meeting times in emails.\"\n",
    ")\n",
    "\n",
    "# Add the debug prompt if user runs with debug\n",
    "if debug:\n",
    "    debug_prompt = (\n",
    "        \"Keep a record of any feedback requests provided by me\"\n",
    "        \" detailing the prompt and tools calls in case I want to retrieve\"\n",
    "        \" them.\"\n",
    "    )\n",
    "else:\n",
    "    debug_prompt = \"\"\n",
    "assistant_instructions += debug_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an OpenAI Assistant so we can interact with it, and a thread in which to run our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AI Administrative Assistant\",\n",
    "    instructions=assistant_instructions,\n",
    "    model=model,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make execution easier in the future steps, we create a function to run prompts with only one call. Then, we are going to use the function to submit the initial coaching prompt so that the Assistant gets better at performing tasks from the beginning. (A big part of the secret sauce of AdminGPT is in the coaching data file called coaching_data.txt, which gives table-stakes knowledge to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt, client, assistant, thread):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt,\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "    )\n",
    "    return run\n",
    "\n",
    "\n",
    "with open(\"coaching_data.txt\", \"r\") as file:\n",
    "    prompt = file = file.read()\n",
    "\n",
    "run = run_prompt(prompt, client, assistant, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further make execution easier in future steps, we Create a function that polls the OpenAI API for a response to the prompt and executes tool calls, so we can use it to retrieve responses in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_for_response(client, thread, run, model, debug=False):\n",
    "    LOOP_DELAY_SECONDS = 3\n",
    "\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        status = run.status\n",
    "\n",
    "        if status == \"completed\":\n",
    "            response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            if response.data:\n",
    "                return response.data[0].content[0].text.value\n",
    "            break\n",
    "        elif status == \"requires_action\":\n",
    "            tools_outputs = []\n",
    "\n",
    "            for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                tool_call_id = tool_call.id\n",
    "                function_name = tool_call.function.name\n",
    "                function_arguments = tool_call.function.arguments\n",
    "                function_arguments = json.loads(function_arguments)\n",
    "\n",
    "                # Case statement to execute each toolkit function\n",
    "                if function_name == \"o365search_emails\":\n",
    "                    output = o365search_emails(**function_arguments)\n",
    "                elif function_name == \"o365search_email\":\n",
    "                    output = o365search_email(**function_arguments)\n",
    "                elif function_name == \"o365search_events\":\n",
    "                    output = o365search_events(**function_arguments)\n",
    "                elif function_name == \"o365parse_proposed_times\":\n",
    "                    output = o365parse_proposed_times(\n",
    "                        **function_arguments, client=client, model=model\n",
    "                    )\n",
    "                elif function_name == \"o365send_message\":\n",
    "                    output = o365send_message(**function_arguments)\n",
    "                elif function_name == \"o365send_event\":\n",
    "                    output = o365send_event(**function_arguments)\n",
    "                elif function_name == \"o365reply_message\":\n",
    "                    output = o365reply_message(**function_arguments)\n",
    "                elif function_name == \"o365find_free_time_slots\":\n",
    "                    output = o365find_free_time_slots(**function_arguments)\n",
    "\n",
    "                # Clean the function output into JSON-like output\n",
    "                output = pprint.pformat(output)\n",
    "                tool_output = {\"tool_call_id\": tool_call_id, \"output\": output}\n",
    "                tools_outputs.append(tool_output)\n",
    "\n",
    "            if run.required_action.type == \"submit_tool_outputs\":\n",
    "                client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread.id, run_id=run.id, tool_outputs=tools_outputs\n",
    "                )\n",
    "\n",
    "        elif status == \"failed\":\n",
    "            return \"Run failed try again!\"\n",
    "            break\n",
    "\n",
    "        if debug:\n",
    "            print(\"The Assistant's Status is: \" + status)\n",
    "\n",
    "        time.sleep(LOOP_DELAY_SECONDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've submit our first prompt, we are going to poll for a response. If the response is, \"How can I help you?\", we know that the coaching data was sent correctly, and we are ready to start using AdminGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Santiago Delgado. How can I help you?\n"
     ]
    }
   ],
   "source": [
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we're going to perform the most simple task, which is summarizing an email from a specific sender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from Santiago Delgado touches on the topic of Mike Portnoy potentially rejoining Dream Theater and asks for your thoughts on the matter. The sender suggests discussing this on February 3, 2024, at 4:00 pm ET. The email reflects on Portnoy's history with the band, his departure in 2010, and his influence on their classic sound. The sender is looking forward to hearing your thoughts on whether Portnoy's return could revitalize the classic Dream Theater sound or lead to complications.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Can you please concisely summarize the most recent email from Santiago Delgado\"\n",
    "    \" including any proposed meeting times?\"\n",
    ")\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to show AdminGPT's ability to interact with your calendar. We're going to check what events we have on the day that the email proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On February 3, 2024, the day Santiago Delgado proposed to meet in his email, you have the following meetings scheduled:\n",
      "\n",
      "1. A flight from Dallas to Cincinnati from 8:00 am to 10:30 am ET.\n",
      "2. A lunch meeting with management from 12:00 pm to 1:00 pm ET.\n",
      "3. A strategy session from 3:00 pm to 5:00 pm ET.\n",
      "4. A flight from Cincinnati to Dallas from 6:00 pm to 8:30 pm ET.\n",
      "\n",
      "The proposed meeting time in Santiago Delgado's email, 4:00 pm ET, conflicts with the strategy session you have scheduled from 3:00 pm to 5:00 pm ET.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"What meetings do I have on the day that Santiago Delgado is proposing to meet in\"\n",
    "    \" his most email?\"\n",
    ")\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know when the email sender wants to meet, and what meetings I have on that day. So, let's see what times I have free that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On February 3, 2024, you have free time during the following periods:\n",
      "\n",
      "1. From 12:00 am to 8:00 am ET.\n",
      "2. From 10:30 am to 12:00 pm ET.\n",
      "3. From 1:00 pm to 3:00 pm ET.\n",
      "4. From 5:00 pm to 6:00 pm ET.\n",
      "5. From 8:30 pm to 11:59 pm ET.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What times am I free on the day that Santiago is proposing to meet?\"\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this information, we can now draft a response to the email letting the sender know that we can't meet at the proposed time, and propose other times to meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have drafted a response to Santiago:\n",
      "\n",
      "---\n",
      "\n",
      "Dear Santiago,\n",
      "\n",
      "Thank you for reaching out with the discussion about Mike Portnoy and Dream Theater. Unfortunately, I am not available at 4:00 pm ET on February 3 as I have a strategy session scheduled during that time.\n",
      "\n",
      "However, I am available to discuss this at other times on the same day. Here are some potential time slots:\n",
      "- 10:30 am to 12:00 pm ET\n",
      "- 1:00 pm to 3:00 pm ET\n",
      "- 5:00 pm to 6:00 pm ET\n",
      "- 8:30 pm to 11:59 pm ET\n",
      "\n",
      "Please let me know if any of these times work for you or if there is an alternate time you had in mind.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "The draft has been saved with the subject \"Mike Portnoy coming back to Dream Theater?\" Would you like me to send it?\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Please draft a response to Santiago letting him know that I can't meet on the\"\n",
    "    \" proposed times, and propose other free times on the same day. Show me the draft.\"\n",
    ")\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we will want the email to come from our AI administrative instead of the ourselves, so we can do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have updated the draft response to Santiago Delgado to come from me on your behalf:\n",
      "\n",
      "---\n",
      "\n",
      "Hi Santiago,\n",
      "\n",
      "I hope this message finds you well. Unfortunately, Santiago will not be available for a discussion at the proposed time of 4:00 pm ET on February 3, as he has a strategy session scheduled at that time.\n",
      "\n",
      "However, Santiago is available at the following times on the same day, and he would be happy to discuss then:\n",
      "- 10:30 am to 12:00 pm ET\n",
      "- 1:00 pm to 3:00 pm ET\n",
      "- 5:00 pm to 6:00 pm ET\n",
      "- 8:30 pm to 11:59 pm ET\n",
      "\n",
      "Please let us know if these alternative times work for you, or if another time would be better for Santiago's schedule.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Monica A. Ingenio\n",
      "Executive Assistant to Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "The draft has been updated and saved with the subject \"Mike Portnoy coming back to Dream Theater?\" Would you like me to send this email now?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you edit the email and have it come from you on behalf of me?\"\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, I want to show that you can follow all these steps in one prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have drafted a response to the most recent email from Santiago Delgado on your behalf:\n",
      "\n",
      "---\n",
      "\n",
      "Dear Santiago,\n",
      "\n",
      "I hope this message finds you well. I am writing on behalf of Santiago Delgado to inform you that he will not be available for the discussion at the proposed time of 4:00 pm ET on February 3rd, due to a prior commitment involving a strategy session.\n",
      "\n",
      "Santiago is available to discuss the matter of Mike Portnoy and Dream Theater at these alternative times on the same day:\n",
      "- 10:30 am to 12:00 pm ET\n",
      "- 1:00 pm to 3:00 pm ET\n",
      "- 5:00 pm to 6:00 pm ET\n",
      "- 8:30 pm onward until the end of the day\n",
      "\n",
      "Please advise if any of these times align with your schedule or if there is a better time for Santiago.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Monica A. Ingenio\n",
      "Executive Assistant to Santiago Delgado\n",
      "\n",
      "---\n",
      "\n",
      "The draft has been saved with the subject \"Mike Portnoy coming back to Dream Theater?\" Would you like me to send it?\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Can you draft a response to Santiago Delgado's most recent email from you on\"\n",
    "    \" behalf of me letting him know if I can meet at the times he proposes, and if not,\"\n",
    "    \" propose other times on the same day? Show me the draft.\"\n",
    ")\n",
    "run = run_prompt(prompt, client, assistant, thread)\n",
    "response = poll_for_response(client, thread, run, model, debug)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
